{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c40f6c",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Downloading-the-dataset\" data-toc-modified-id=\"Downloading-the-dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Downloading the dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Audio-dataset\" data-toc-modified-id=\"Audio-dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Audio dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#loadign-the-catalog-of-the-cleaned-data-for-train-dataset\" data-toc-modified-id=\"loadign-the-catalog-of-the-cleaned-data-for-train-dataset-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>loadign the catalog of the cleaned data for train dataset</a></span></li><li><span><a href=\"#some-packages-to-download-the-audio-files\" data-toc-modified-id=\"some-packages-to-download-the-audio-files-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>some packages to download the audio files</a></span></li><li><span><a href=\"#normalisation-of-the-audio-tracks\" data-toc-modified-id=\"normalisation-of-the-audio-tracks-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>normalisation of the audio tracks</a></span></li></ul></li><li><span><a href=\"#Video-dataset\" data-toc-modified-id=\"Video-dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Video dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#face-detection-from-the-raw-frame\" data-toc-modified-id=\"face-detection-from-the-raw-frame-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>face detection from the raw frame</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0146417e",
   "metadata": {},
   "source": [
    "# Downloading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487af069",
   "metadata": {},
   "source": [
    "## Audio dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb2aa61a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (369929723.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [2]\u001b[0;36m\u001b[0m\n\u001b[0;31m    from tensorflow.python\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417bdbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and preprocess the data from AVspeech dataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "# pip install librosa\n",
    "sys.path.append(\"../cocktail_effect/data\")  # path to the AVHandler.py\n",
    "import AVHandler as avh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62bc6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_link(youtube_id):\n",
    "    # return the youtube actual link\n",
    "    link = 'https://www.youtube.com/watch?v='+ youtube_id\n",
    "    return link\n",
    "\n",
    "def m_audio(loc, name, cat, start_idx, end_idx):\n",
    "    # make concatenated audio following by the catalog from AVSpeech\n",
    "    # loc       | the location for file to store\n",
    "    # name      | name for the wav mix file\n",
    "    # cat       | the catalog with audio link and time\n",
    "    # start_idx | the starting index of the audio to download and concatenate\n",
    "    # end_idx   | the ending index of the audio to download and concatenate\n",
    "\n",
    "    for i in range(start_idx, end_idx):\n",
    "        f_name = name+str(i)\n",
    "        link = m_link(cat.loc[i,'link'])\n",
    "        start_time = cat.loc[i,'start_time']\n",
    "        end_time = start_time + 3.0\n",
    "        avh.download(loc,f_name,link)\n",
    "        avh.cut(loc,f_name,start_time,end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91cb7a8",
   "metadata": {},
   "source": [
    "### loadign the catalog of the cleaned data for train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09606576",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"link\", \"start_time\", \"end_time\", \"x_coord\", \"y_coord\"]\n",
    "cat_train = pd.read_csv('../raw_data/avspeech_train.csv', names=header)\n",
    "#cat_test = pd.read_csv('catalog/avspeech_test.csv', names=header)\n",
    "cat_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a2956d",
   "metadata": {},
   "source": [
    "### some packages to download the audio files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24916f4",
   "metadata": {},
   "source": [
    "SoX is a cross-platform (Windows, Linux, MacOS X, etc.) command line utility that can convert various formats of computer audio files in to other formats. more on [SoX](http://sox.sourceforge.net/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf43c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install youtube-dl\n",
    "# !brew install ffmpeg   # for converting, recording and streaming audio and videos\n",
    "# !brew install sox      # SoX - Sound eXchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81108120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avh.mkdir('audio_train')  # audio_train model is created in the notebook folder\n",
    "m_audio('audio_train','audio_train',cat_train, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87617b5",
   "metadata": {},
   "source": [
    "### normalisation of the audio tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e33a2f",
   "metadata": {},
   "source": [
    "In the AVHandler sampling rate of the audio files are set to 16000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12532d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import audio_norm\n",
    "audio_norm  # This will make a new folder (norm_audio_trian) with normalised audio tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3e917",
   "metadata": {},
   "source": [
    "## Video dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a57da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "sys.path.append(\"../models/lib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188f0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_download(loc,cat,start_idx,end_idx):\n",
    "    # Only download the video from the link\n",
    "    # loc        | the location for downloaded file\n",
    "    # v_name     | the name for the video file\n",
    "    # cat        | the catalog with audio link and time\n",
    "    # start_idx  | the starting index of the video to download\n",
    "    # end_idx    | the ending index of the video to download\n",
    "\n",
    "    for i in range(start_idx,end_idx):\n",
    "        command = 'cd %s;' % loc\n",
    "        f_name = str(i)\n",
    "        link = avh.m_link(cat.loc[i, 'link'])\n",
    "        start_time = cat.loc[i, 'start_time']\n",
    "        end_time = start_time + 3.0\n",
    "        start_time = datetime.timedelta(seconds=start_time)\n",
    "        end_time = datetime.timedelta(seconds=end_time)\n",
    "        command += 'ffmpeg -i $(youtube-dl -f ”mp4“ --get-url ' + link + ') ' + '-c:v h264 -c:a copy -ss %s -to %s %s.mp4' \\\n",
    "                % (start_time, end_time, f_name)\n",
    "        os.system(command)\n",
    "    \n",
    "def generate_frames(loc, start_idx, end_idx):\n",
    "    # get frames for each video clip\n",
    "    # loc        | the location of video clip\n",
    "    # v_name     | v_name = 'clip_video_train'\n",
    "    # start_idx  | the starting index of the training sample\n",
    "    # end_idx    | the ending index of the training sample\n",
    "\n",
    "    avh.mkdir('frames')\n",
    "    for i in range(start_idx, end_idx):\n",
    "        command = 'cd %s;' % loc\n",
    "        f_name = str(i)\n",
    "        command += 'ffmpeg -i %s.mp4 -y -f image2  -vframes 75 ../frames/%s-%%02d.jpg' % (\n",
    "            f_name, f_name)\n",
    "        os.system(command)\n",
    "\n",
    "\n",
    "def download_video_frames(loc, cat, start_idx, end_idx, rm_video):\n",
    "    # Download each video and convert to frames immediately, can choose to remove video file\n",
    "    # loc        | the location for downloaded file\n",
    "    # cat        | the catalog with audio link and time\n",
    "    # start_idx  | the starting index of the video to download\n",
    "    # end_idx    | the ending index of the video to download\n",
    "    # rm_video   | boolean value for delete video and only keep the frames\n",
    "\n",
    "    avh.mkdir('frames')\n",
    "    for i in range(start_idx, end_idx + 1):\n",
    "        command = 'cd %s;' % loc\n",
    "        f_name = str(i)\n",
    "        link = avh.m_link(cat.loc[i, 'link'])\n",
    "        start_time = cat.loc[i, 'start_time']\n",
    "        end_time = start_time + 3.0\n",
    "        start_time = datetime.timedelta(seconds=start_time)\n",
    "        end_time = datetime.timedelta(seconds=end_time)\n",
    "        command += 'ffmpeg -i $(youtube-dl -f ”mp4“ --get-url ' + link + ') ' + '-c:v h264 -c:a copy -ss %s -to %s %s.mp4;' \\\n",
    "                   % (start_time, end_time, f_name)\n",
    "        command += 'ffmpeg -i %s.mp4 -vf fps=25 ../frames/%s-%%02d.jpg;' % (\n",
    "            f_name, f_name)\n",
    "        if rm_video:\n",
    "            command += 'rm %s.mp4' % f_name\n",
    "        os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c743dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "avh.mkdir('video_train')\n",
    "\n",
    "# download video , convert to images separately\n",
    "#avh.video_download(loc='video_train',v_name='video_train',cat=cat_train,start_idx=2,end_idx=4)\n",
    "#avh.generate_frames(loc='video_train',v_name='clip_video_train',start_idx=2,end_idx=4)\n",
    "\n",
    "# download each video and convert to frames immediately\n",
    "download_video_frames(loc='video_train',\n",
    "                      cat=cat_train,\n",
    "                      start_idx=1,\n",
    "                      end_idx=2,\n",
    "                      rm_video=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be95bb",
   "metadata": {},
   "source": [
    "### face detection from the raw frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf27a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a85d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"link\", \"start_time\", \"end_time\", \"x_coord\", \"y_coord\"]\n",
    "cat_train = pd.read_csv('../raw_data/avspeech_train.csv', names=header)\n",
    "#cat_test = pd.read_csv('catalog/avspeech_test.csv', names=header)\n",
    "cat_train.head()\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "cat_train = pd.read_csv('../raw_data/avspeech_train.csv')\n",
    "frame_path = './frames/'\n",
    "output_dir = './face_input'\n",
    "detect_range = (1, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

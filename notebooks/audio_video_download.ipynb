{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c40f6c",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Downloading-the-dataset\" data-toc-modified-id=\"Downloading-the-dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Downloading the dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Audio-dataset\" data-toc-modified-id=\"Audio-dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Audio dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#loadign-the-catalog-of-the-cleaned-data-for-train-dataset\" data-toc-modified-id=\"loadign-the-catalog-of-the-cleaned-data-for-train-dataset-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>loadign the catalog of the cleaned data for train dataset</a></span></li><li><span><a href=\"#some-packages-to-download-the-audio-files\" data-toc-modified-id=\"some-packages-to-download-the-audio-files-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>some packages to download the audio files</a></span></li><li><span><a href=\"#normalisation-of-the-audio-tracks\" data-toc-modified-id=\"normalisation-of-the-audio-tracks-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>normalisation of the audio tracks</a></span></li></ul></li><li><span><a href=\"#Video-dataset\" data-toc-modified-id=\"Video-dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Video dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#face-detection-from-the-raw-frame\" data-toc-modified-id=\"face-detection-from-the-raw-frame-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>face detection from the raw frame</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0146417e",
   "metadata": {},
   "source": [
    "# Downloading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487af069",
   "metadata": {},
   "source": [
    "## Audio dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417bdbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and preprocess the data from AVspeech dataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "# pip install librosa\n",
    "sys.path.append(\"../cocktail_effect/data\")  # path to the AVHandler.py\n",
    "import AVHandler as avh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62bc6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_link(youtube_id):\n",
    "    # return the youtube actual link\n",
    "    link = 'https://www.youtube.com/watch?v='+ youtube_id\n",
    "    return link\n",
    "\n",
    "def m_audio(loc, name, cat, start_idx, end_idx):\n",
    "    # make concatenated audio following by the catalog from AVSpeech\n",
    "    # loc       | the location for file to store\n",
    "    # name      | name for the wav mix file\n",
    "    # cat       | the catalog with audio link and time\n",
    "    # start_idx | the starting index of the audio to download and concatenate\n",
    "    # end_idx   | the ending index of the audio to download and concatenate\n",
    "\n",
    "    for i in range(start_idx, end_idx):\n",
    "        f_name = name+str(i)\n",
    "        link = m_link(cat.loc[i,'link'])\n",
    "        start_time = cat.loc[i,'start_time']\n",
    "        end_time = start_time + 3.0\n",
    "        avh.download(loc,f_name,link)\n",
    "        avh.cut(loc,f_name,start_time,end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91cb7a8",
   "metadata": {},
   "source": [
    "### loadign the catalog of the cleaned data for train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09606576",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"link\", \"start_time\", \"end_time\", \"x_coord\", \"y_coord\"]\n",
    "cat_train = pd.read_csv('../raw_data/avspeech_train.csv', names=header)\n",
    "#cat_test = pd.read_csv('catalog/avspeech_test.csv', names=header)\n",
    "cat_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a2956d",
   "metadata": {},
   "source": [
    "### some packages to download the audio files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24916f4",
   "metadata": {},
   "source": [
    "SoX is a cross-platform (Windows, Linux, MacOS X, etc.) command line utility that can convert various formats of computer audio files in to other formats. more on [SoX](http://sox.sourceforge.net/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf43c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install youtube-dl\n",
    "# !brew install ffmpeg   # for converting, recording and streaming audio and videos\n",
    "# !brew install sox      # SoX - Sound eXchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81108120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avh.mkdir('audio_train')  # audio_train model is created in the notebook folder\n",
    "m_audio('audio_train','audio_train',cat_train, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87617b5",
   "metadata": {},
   "source": [
    "### normalisation of the audio tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e33a2f",
   "metadata": {},
   "source": [
    "In the AVHandler sampling rate of the audio files are set to 16000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12532d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import audio_norm\n",
    "audio_norm  # This will make a new folder (norm_audio_trian) with normalised audio tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3e917",
   "metadata": {},
   "source": [
    "## Video dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a57da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "sys.path.append(\"../models/lib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188f0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_download(loc,cat,start_idx,end_idx):\n",
    "    # Only download the video from the link\n",
    "    # loc        | the location for downloaded file\n",
    "    # v_name     | the name for the video file\n",
    "    # cat        | the catalog with audio link and time\n",
    "    # start_idx  | the starting index of the video to download\n",
    "    # end_idx    | the ending index of the video to download\n",
    "\n",
    "    for i in range(start_idx,end_idx):\n",
    "        command = 'cd %s;' % loc\n",
    "        f_name = str(i)\n",
    "        link = avh.m_link(cat.loc[i, 'link'])\n",
    "        start_time = cat.loc[i, 'start_time']\n",
    "        end_time = start_time + 3.0\n",
    "        start_time = datetime.timedelta(seconds=start_time)\n",
    "        end_time = datetime.timedelta(seconds=end_time)\n",
    "        command += 'ffmpeg -i $(youtube-dl -f ”mp4“ --get-url ' + link + ') ' + '-c:v h264 -c:a copy -ss %s -to %s %s.mp4' \\\n",
    "                % (start_time, end_time, f_name)\n",
    "        os.system(command)\n",
    "    \n",
    "def generate_frames(loc, start_idx, end_idx):\n",
    "    # get frames for each video clip\n",
    "    # loc        | the location of video clip\n",
    "    # v_name     | v_name = 'clip_video_train'\n",
    "    # start_idx  | the starting index of the training sample\n",
    "    # end_idx    | the ending index of the training sample\n",
    "\n",
    "    avh.mkdir('frames')\n",
    "    for i in range(start_idx, end_idx):\n",
    "        command = 'cd %s;' % loc\n",
    "        f_name = str(i)\n",
    "        command += 'ffmpeg -i %s.mp4 -y -f image2  -vframes 75 ../frames/%s-%%02d.jpg' % (\n",
    "            f_name, f_name)\n",
    "        os.system(command)\n",
    "\n",
    "\n",
    "def download_video_frames(loc, cat, start_idx, end_idx, rm_video):\n",
    "    # Download each video and convert to frames immediately, can choose to remove video file\n",
    "    # loc        | the location for downloaded file\n",
    "    # cat        | the catalog with audio link and time\n",
    "    # start_idx  | the starting index of the video to download\n",
    "    # end_idx    | the ending index of the video to download\n",
    "    # rm_video   | boolean value for delete video and only keep the frames\n",
    "\n",
    "    avh.mkdir('frames')\n",
    "    for i in range(start_idx, end_idx + 1):\n",
    "        command = 'cd %s;' % loc\n",
    "        f_name = str(i)\n",
    "        link = avh.m_link(cat.loc[i, 'link'])\n",
    "        start_time = cat.loc[i, 'start_time']\n",
    "        end_time = start_time + 3.0\n",
    "        start_time = datetime.timedelta(seconds=start_time)\n",
    "        end_time = datetime.timedelta(seconds=end_time)\n",
    "        command += 'ffmpeg -i $(youtube-dl -f ”mp4“ --get-url ' + link + ') ' + '-c:v h264 -c:a copy -ss %s -to %s %s.mp4;' \\\n",
    "                   % (start_time, end_time, f_name)\n",
    "        command += 'ffmpeg -i %s.mp4 -vf fps=25 ../frames/%s-%%02d.jpg;' % (\n",
    "            f_name, f_name)\n",
    "        if rm_video:\n",
    "            command += 'rm %s.mp4' % f_name\n",
    "        os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c743dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "avh.mkdir('video_train')\n",
    "\n",
    "# download video , convert to images separately\n",
    "#avh.video_download(loc='video_train',v_name='video_train',cat=cat_train,start_idx=2,end_idx=4)\n",
    "#avh.generate_frames(loc='video_train',v_name='clip_video_train',start_idx=2,end_idx=4)\n",
    "\n",
    "# download each video and convert to frames immediately\n",
    "download_video_frames(loc='video_train',\n",
    "                      cat=cat_train,\n",
    "                      start_idx=1,\n",
    "                      end_idx=2,\n",
    "                      rm_video=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be95bb",
   "metadata": {},
   "source": [
    "### face detection from the raw frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf27a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from mtcnn_cv2 import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d3f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a85d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"link\", \"start_time\", \"end_time\", \"x_coord\", \"y_coord\"]\n",
    "cat_train = pd.read_csv('../raw_data/avspeech_train.csv', names=header)\n",
    "#cat_test = pd.read_csv('catalog/avspeech_test.csv', names=header)\n",
    "cat_train.head()\n",
    "frame_path = './frames/'\n",
    "output_dir = './face_input'\n",
    "detect_range = (1, 2)\n",
    "cat_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee83bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('./face_input'):\n",
    "    os.mkdir('./face_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca849dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box_check(faces, x, y):\n",
    "    # check the center\n",
    "    for face in faces:\n",
    "        bounding_box = face['box']\n",
    "        if (bounding_box[1] < 0):\n",
    "            bounding_box[1] = 0\n",
    "        if (bounding_box[0] < 0):\n",
    "            bounding_box[0] = 0\n",
    "        if (bounding_box[0] - 50 > x\n",
    "                or bounding_box[0] + bounding_box[2] + 50 < x):\n",
    "            print('change person from')\n",
    "            print(bounding_box)\n",
    "            print('to')\n",
    "            continue\n",
    "        if (bounding_box[1] - 50 > y\n",
    "                or bounding_box[1] + bounding_box[3] + 50 < y):\n",
    "            print('change person from')\n",
    "            print(bounding_box)\n",
    "            print('to')\n",
    "            continue\n",
    "        return bounding_box\n",
    "\n",
    "def face_detect(file, detector, frame_path=frame_path, cat_train=cat_train):\n",
    "    name = file.replace('.jpg', '').split('-')\n",
    "    log = cat_train.iloc[int(name[0])]\n",
    "    x = log.iloc[3]\n",
    "    y = log.iloc[4]\n",
    "\n",
    "    img = cv2.imread('%s%s' % (frame_path, file))\n",
    "    x = img.shape[1] * x\n",
    "    y = img.shape[0] * y\n",
    "    faces = detector.detect_faces(img)\n",
    "    # check if detected faces\n",
    "    if (len(faces) == 0):\n",
    "        print('no face detect: ' + file)\n",
    "        return  #no face\n",
    "    bounding_box = bounding_box_check(faces, x, y)\n",
    "    if (bounding_box == None):\n",
    "        print('face is not related to given coord: ' + file)\n",
    "        return\n",
    "    print(file, \" \", bounding_box)\n",
    "    print(file, \" \", x, y)\n",
    "    crop_img = img[bounding_box[1]:bounding_box[1] + bounding_box[3],\n",
    "                   bounding_box[0]:bounding_box[0] + bounding_box[2]]\n",
    "    crop_img = cv2.resize(crop_img, (160, 160))\n",
    "    cv2.imwrite('%s/frame_' % output_dir + name[0] + '_' + name[1] + '.jpg',\n",
    "                crop_img)\n",
    "    #crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)\n",
    "    #plt.imshow(crop_img)\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c76ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_range[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6616c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()\n",
    "for i in range(detect_range[0], detect_range[1]):\n",
    "    for j in range(1, 76): # as there is only 75 frames\n",
    "        file_name = \"%d-%02d.jpg\" % (i, j)\n",
    "        if (not os.path.exists('%s%s' % (frame_path, file_name))):\n",
    "            print('cannot find input: ' + '%s%s' % (frame_path, file_name))\n",
    "            continue\n",
    "        face_detect(file_name, detector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd01f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "csv_path = '../raw_data/avspeech_train.csv'\n",
    "frame_dir = './frames/'\n",
    "output_dir = './face_input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc900fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cocktail_effect import FaceDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b55244fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detec = FaceDetector(csv_path, frame_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21e6d9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-01.jpg   [596, 45, 298, 382]\n",
      "1-01.jpg   647.33312 173.33352000000002\n",
      "1-02.jpg   [596, 48, 296, 377]\n",
      "1-02.jpg   647.33312 173.33352000000002\n",
      "1-03.jpg   [593, 43, 299, 384]\n",
      "1-03.jpg   647.33312 173.33352000000002\n",
      "1-04.jpg   [593, 44, 299, 386]\n",
      "1-04.jpg   647.33312 173.33352000000002\n",
      "1-05.jpg   [593, 44, 297, 379]\n",
      "1-05.jpg   647.33312 173.33352000000002\n",
      "1-06.jpg   [592, 44, 297, 379]\n",
      "1-06.jpg   647.33312 173.33352000000002\n",
      "1-07.jpg   [591, 42, 297, 380]\n",
      "1-07.jpg   647.33312 173.33352000000002\n",
      "1-08.jpg   [590, 40, 297, 383]\n",
      "1-08.jpg   647.33312 173.33352000000002\n",
      "1-09.jpg   [590, 42, 297, 384]\n",
      "1-09.jpg   647.33312 173.33352000000002\n",
      "1-10.jpg   [590, 41, 298, 383]\n",
      "1-10.jpg   647.33312 173.33352000000002\n",
      "1-11.jpg   [589, 39, 298, 384]\n",
      "1-11.jpg   647.33312 173.33352000000002\n",
      "1-12.jpg   [589, 40, 299, 382]\n",
      "1-12.jpg   647.33312 173.33352000000002\n",
      "1-13.jpg   [589, 38, 297, 382]\n",
      "1-13.jpg   647.33312 173.33352000000002\n",
      "1-14.jpg   [589, 43, 296, 378]\n",
      "1-14.jpg   647.33312 173.33352000000002\n",
      "1-15.jpg   [588, 44, 295, 375]\n",
      "1-15.jpg   647.33312 173.33352000000002\n",
      "1-16.jpg   [585, 42, 298, 379]\n",
      "1-16.jpg   647.33312 173.33352000000002\n",
      "1-17.jpg   [584, 42, 300, 377]\n",
      "1-17.jpg   647.33312 173.33352000000002\n",
      "1-18.jpg   [588, 42, 295, 375]\n",
      "1-18.jpg   647.33312 173.33352000000002\n",
      "1-19.jpg   [585, 44, 295, 379]\n",
      "1-19.jpg   647.33312 173.33352000000002\n",
      "1-20.jpg   [584, 42, 298, 384]\n",
      "1-20.jpg   647.33312 173.33352000000002\n",
      "1-21.jpg   [584, 44, 298, 383]\n",
      "1-21.jpg   647.33312 173.33352000000002\n",
      "1-22.jpg   [583, 45, 297, 382]\n",
      "1-22.jpg   647.33312 173.33352000000002\n",
      "1-23.jpg   [587, 49, 302, 383]\n",
      "1-23.jpg   647.33312 173.33352000000002\n",
      "1-24.jpg   [581, 52, 295, 378]\n",
      "1-24.jpg   647.33312 173.33352000000002\n",
      "1-25.jpg   [580, 50, 296, 380]\n",
      "1-25.jpg   647.33312 173.33352000000002\n",
      "1-26.jpg   [578, 46, 300, 384]\n",
      "1-26.jpg   647.33312 173.33352000000002\n",
      "1-27.jpg   [578, 44, 299, 383]\n",
      "1-27.jpg   647.33312 173.33352000000002\n",
      "1-28.jpg   [579, 45, 299, 379]\n",
      "1-28.jpg   647.33312 173.33352000000002\n",
      "1-29.jpg   [583, 47, 297, 370]\n",
      "1-29.jpg   647.33312 173.33352000000002\n",
      "1-30.jpg   [579, 43, 304, 380]\n",
      "1-30.jpg   647.33312 173.33352000000002\n",
      "1-31.jpg   [578, 40, 303, 387]\n",
      "1-31.jpg   647.33312 173.33352000000002\n",
      "1-32.jpg   [578, 39, 304, 385]\n",
      "1-32.jpg   647.33312 173.33352000000002\n",
      "1-33.jpg   [578, 40, 305, 386]\n",
      "1-33.jpg   647.33312 173.33352000000002\n",
      "1-34.jpg   [580, 36, 304, 389]\n",
      "1-34.jpg   647.33312 173.33352000000002\n",
      "1-35.jpg   [580, 34, 304, 391]\n",
      "1-35.jpg   647.33312 173.33352000000002\n",
      "1-36.jpg   [583, 37, 303, 387]\n",
      "1-36.jpg   647.33312 173.33352000000002\n",
      "1-37.jpg   [585, 37, 303, 384]\n",
      "1-37.jpg   647.33312 173.33352000000002\n",
      "1-38.jpg   [586, 36, 302, 383]\n",
      "1-38.jpg   647.33312 173.33352000000002\n",
      "1-39.jpg   [587, 35, 301, 383]\n",
      "1-39.jpg   647.33312 173.33352000000002\n",
      "1-40.jpg   [587, 34, 301, 386]\n",
      "1-40.jpg   647.33312 173.33352000000002\n",
      "1-41.jpg   [586, 35, 304, 390]\n",
      "1-41.jpg   647.33312 173.33352000000002\n",
      "1-42.jpg   [586, 33, 305, 394]\n",
      "1-42.jpg   647.33312 173.33352000000002\n",
      "1-43.jpg   [587, 35, 300, 386]\n",
      "1-43.jpg   647.33312 173.33352000000002\n",
      "1-44.jpg   [587, 34, 300, 379]\n",
      "1-44.jpg   647.33312 173.33352000000002\n",
      "1-45.jpg   [586, 32, 302, 381]\n",
      "1-45.jpg   647.33312 173.33352000000002\n",
      "1-46.jpg   [585, 31, 301, 386]\n",
      "1-46.jpg   647.33312 173.33352000000002\n",
      "1-47.jpg   [584, 28, 306, 395]\n",
      "1-47.jpg   647.33312 173.33352000000002\n",
      "1-48.jpg   [583, 25, 308, 395]\n",
      "1-48.jpg   647.33312 173.33352000000002\n",
      "1-49.jpg   [592, 32, 292, 374]\n",
      "1-49.jpg   647.33312 173.33352000000002\n",
      "1-50.jpg   [592, 18, 298, 385]\n",
      "1-50.jpg   647.33312 173.33352000000002\n",
      "1-51.jpg   [587, 6, 306, 391]\n",
      "1-51.jpg   647.33312 173.33352000000002\n",
      "1-52.jpg   [586, 0, 308, 388]\n",
      "1-52.jpg   647.33312 173.33352000000002\n",
      "1-53.jpg   [591, 0, 302, 377]\n",
      "1-53.jpg   647.33312 173.33352000000002\n",
      "1-54.jpg   [587, 0, 303, 368]\n",
      "1-54.jpg   647.33312 173.33352000000002\n",
      "1-55.jpg   [585, 0, 306, 366]\n",
      "1-55.jpg   647.33312 173.33352000000002\n",
      "1-56.jpg   [586, 0, 303, 369]\n",
      "1-56.jpg   647.33312 173.33352000000002\n",
      "1-57.jpg   [588, 0, 302, 376]\n",
      "1-57.jpg   647.33312 173.33352000000002\n",
      "1-58.jpg   [588, 0, 299, 374]\n",
      "1-58.jpg   647.33312 173.33352000000002\n",
      "1-59.jpg   [578, 0, 306, 387]\n",
      "1-59.jpg   647.33312 173.33352000000002\n",
      "1-60.jpg   [579, 10, 302, 384]\n",
      "1-60.jpg   647.33312 173.33352000000002\n",
      "1-61.jpg   [575, 14, 307, 390]\n",
      "1-61.jpg   647.33312 173.33352000000002\n",
      "1-62.jpg   [573, 13, 310, 397]\n",
      "1-62.jpg   647.33312 173.33352000000002\n",
      "1-63.jpg   [572, 12, 312, 400]\n",
      "1-63.jpg   647.33312 173.33352000000002\n",
      "1-64.jpg   [571, 9, 312, 400]\n",
      "1-64.jpg   647.33312 173.33352000000002\n",
      "1-65.jpg   [575, 8, 307, 396]\n",
      "1-65.jpg   647.33312 173.33352000000002\n",
      "1-66.jpg   [570, 3, 314, 401]\n",
      "1-66.jpg   647.33312 173.33352000000002\n",
      "1-67.jpg   [575, 6, 308, 392]\n",
      "1-67.jpg   647.33312 173.33352000000002\n",
      "1-68.jpg   [575, 0, 309, 395]\n",
      "1-68.jpg   647.33312 173.33352000000002\n",
      "1-69.jpg   [571, 0, 307, 389]\n",
      "1-69.jpg   647.33312 173.33352000000002\n",
      "1-70.jpg   [570, 0, 306, 383]\n",
      "1-70.jpg   647.33312 173.33352000000002\n",
      "1-71.jpg   [574, 0, 308, 373]\n",
      "1-71.jpg   647.33312 173.33352000000002\n",
      "1-72.jpg   [573, 0, 305, 375]\n",
      "1-72.jpg   647.33312 173.33352000000002\n",
      "1-73.jpg   [575, 0, 308, 366]\n",
      "1-73.jpg   647.33312 173.33352000000002\n",
      "1-74.jpg   [581, 0, 305, 343]\n",
      "1-74.jpg   647.33312 173.33352000000002\n",
      "1-75.jpg   [578, 0, 309, 339]\n",
      "1-75.jpg   647.33312 173.33352000000002\n"
     ]
    }
   ],
   "source": [
    "face_detec.detect((1,2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
